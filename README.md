# Anomaly-Event-Detection
## Traffic Anomaly Detection(TAD)
### 2024
- Trafficvlm: A controllable visual language model for traffic video captioning (**CVPR** 2024) [[paper]](https://openaccess.thecvf.com/content/CVPR2024W/AICity/html/Dinh_TrafficVLM_A_Controllable_Visual_Language_Model_for_Traffic_Video_Captioning_CVPRW_2024_paper.html) [[code]](https://github.com/quangminhdinh/TrafficVLM)
- What Matters in Autonomous Driving Anomaly Detection: A Weakly Supervised Horizon (**ECCV ORAL** 2024) [[paper]](https://arxiv.org/abs/2408.05562) [[code]](https://github.com/ut21/WSAD-Driving)
- Memory-Augmented Online Video Anomaly Detection (**ICASSP** 2024) [[paper]](https://ieeexplore.ieee.org/abstract/document/10447554) [[code]](https://github.com/IMPLabUniPr/movad/tree/movad_vad)
### 2023
- Drama: Joint risk localization and captioning in driving (**WACV** 2023) [[paper]](https://openaccess.thecvf.com/content/WACV2023/html/Malla_DRAMA_Joint_Risk_Localization_and_Captioning_in_Driving_WACV_2023_paper.html)
- DoTA: Unsupervised Detection of Traffic Anomaly in Driving Videos (**TPAMI** 2023) [[paper]](https://ieeexplore.ieee.org/abstract/document/9712446) [[code]](https://github.com/MoonBlvd/Detection-of-Traffic-Anomaly)
### 2022
- Spatio-Temporal Feature Encoding for Traffic Accident Detection in VANET Environment (**TITS** 2022) [[paper]](https://ieeexplore.ieee.org/abstract/document/9714213)
- Traffic Accident Detection via Self-Supervised Consistency Learning in Driving Scenarios (**TITS** 2022) [[paper]](https://ieeexplore.ieee.org/abstract/document/9733965)
### 2020
- Towards Anomaly Detection in Dashcam Videos (**IV** 2020) [[paper]](https://ieeexplore.ieee.org/abstract/document/9304576)
### 2019
- Unsupervised traffic accident detection in first-person videos (**IROS** 2019) [[paper]](https://ieeexplore.ieee.org/abstract/document/8967556) [[code]](https://github.com/MoonBlvd/tad-IROS2019)

## Traffic Anomaly Anticipation(TAA)
### 2024
- Graph(Graph): A Nested Graph-Based Framework for Early Accident Anticipation (**WACV** 2024) [[paper]](https://openaccess.thecvf.com/content/WACV2024/html/Thakur_GraphGraph_A_Nested_Graph-Based_Framework_for_Early_Accident_Anticipation_WACV_2024_paper.html) [[code]](https://github.com/thakurnupur/Graph-Graph)
- Abductive Ego-View Accident Video Understanding for Safe Driving Perception (**CVPR** 2024) [[paper]](https://openaccess.thecvf.com/content/CVPR2024/html/Fang_Abductive_Ego-View_Accident_Video_Understanding_for_Safe_Driving_Perception_CVPR_2024_paper.html) [[code]](https://github.com/jeffreychou777/LOTVS-MM-AU)
### 2023
- Cognitive Accident Prediction in Driving Scenes: A Multimodality Benchmark [[paper]](https://arxiv.org/abs/2212.09381) [[code]](https://github.com/JWFanggit/LOTVS-CAP)

### 2022
- An attention-guided multistream feature fusion network for localization of risky objects in driving videos (**TITS** 2022) [[paper]](https://arxiv.org/abs/2209.07922) [[code]](https://github.com/monjurulkarim/risky_object)
- A Dynamic Spatial-Temporal Attention Network for Early Anticipation of Traffic Accidents (**TITS** 2022) [[paper]](https://ieeexplore.ieee.org/abstract/document/9732278) [[code]](https://github.com/monjurulkarim/DSTA)

## Video Anomaly Detection(VAD)
### 2024
- Self-Distilled Masked Auto-Encoders are Efficient Video Anomaly Detectors (**CVPR** 2024) [[paper]](https://openaccess.thecvf.com/content/CVPR2024/html/Ristea_Self-Distilled_Masked_Auto-Encoders_are_Efficient_Video_Anomaly_Detectors_CVPR_2024_paper.html) [[code]](https://github.com/ristea/aed-mae) 

## Image Anomaly Detection
### 2024
- Self-supervised likelihood estimation with energy guidance for anomaly segmentation in urban scenes (**AAAI** 2024) [[paper]](https://ojs.aaai.org/index.php/AAAI/article/view/30162) [[code]](https://github.com/yuanpengtu/SLEEG)
- Diffusion for Out-of-Distribution Detection on Road Scenes and Beyond (**ECCV** 2024) [[paper]](https://arxiv.org/abs/2407.15739)
- OoDIS: Anomaly Instance Segmentation Benchmark (**CVPR** 2024) [[paper]](https://arxiv.org/abs/2406.11835) [[code]](https://github.com/kumuji/ugains)
- Placing Objects in Context via Inpainting for Out-of-distribution Segmentation (**ECCV** 2024) [[paper]](https://arxiv.org/abs/2402.16392) [[code]](https://github.com/naver/poc)
- Random Walk on Pixel Manifolds for Anomaly Segmentation of Complex Driving Scenes (**ECCV** 2024) [[paper]](https://arxiv.org/abs/2404.17961) [[code]](https://github.com/zelongzeng/rwpm)
- Segment Every Out-of-Distribution Object (**CVPR** 2024) [[paper]](https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Segment_Every_Out-of-Distribution_Object_CVPR_2024_paper.html) [[code]](https://github.com/WenjieZhao1/S2M)
### 2023
- Unmasking anomalies in road-scene segmentation (**ICCV ORAL** 2023) [[paper]](https://openaccess.thecvf.com/content/ICCV2023/html/Nandan_Unmasking_Anomalies_in_Road-Scene_Segmentation_ICCV_2023_paper.html) [[code]](https://github.com/shyam671/Mask2Anomaly-Unmasking-Anomalies-in-Road-Scene-Segmentation)
- On Advantages of Mask-level Recognition for Outlier-aware Segmentation (**CVPR** 2023) [[paper]](https://openaccess.thecvf.com/content/CVPR2023W/VAND/html/Grcic_On_Advantages_of_Mask-Level_Recognition_for_Outlier-Aware_Segmentation_CVPRW_2023_paper.html)
- Balanced Energy Regularization Loss for Out-of-distribution Detection (**CVPR** 2023) [[paper]](https://openaccess.thecvf.com/content/CVPR2023/html/Choi_Balanced_Energy_Regularization_Loss_for_Out-of-Distribution_Detection_CVPR_2023_paper.html)
- Residual Pattern Learning for Pixel-wise Out-of-Distribution Detection in Semantic Segmentation (**ICCV** 2023) [[paper]](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Residual_Pattern_Learning_for_Pixel-Wise_Out-of-Distribution_Detection_in_Semantic_Segmentation_ICCV_2023_paper.html) [[code]](https://github.com/yyliu01/RPL)
- Image-Consistent Detection of Road Anomalies as Unpredictable Patches (**WACV** 2023) [[paper]](https://openaccess.thecvf.com/content/WACV2023/html/Vojir_Image-Consistent_Detection_of_Road_Anomalies_As_Unpredictable_Patches_WACV_2023_paper.html)
- Anomaly-Aware Semantic Segmentation via Style-Aligned OoD Augmentation (**ICCV** 2023) [[paper]](https://openaccess.thecvf.com/content/ICCV2023W/BRAVO/html/Zhang_Anomaly-Aware_Semantic_Segmentation_via_Style-Aligned_OoD_Augmentation_ICCVW_2023_paper.html)
- Unsupervised Road Anomaly Detection with Language Anchors (**ICRA** 2023) [[paper]](https://ieeexplore.ieee.org/abstract/document/10160470) [[code]](https://github.com/TB5z035/URAD-LA.git)
- Far Away in the Deep Space: Dense Nearest-Neighbor-Based Out-of-Distribution Detection (**ICCV** 2023) [[paper]](https://openaccess.thecvf.com/content/ICCV2023W/UnCV/html/Galesso_Far_Away_in_the_Deep_Space_Dense_Nearest-Neighbor-Based_Out-of-Distribution_Detection_ICCVW_2023_paper.html) 
### 2022
- Pixel-wise Energy-biased Abstention Learning for Anomaly Segmentation on Complex Urban Driving Scenes (**ECCV** 2022) [[paper]](https://link.springer.com/chapter/10.1007/978-3-031-19842-7_15) [[code]](https://github.com/tianyu0207/PEBAL)
### 2021
- Standardized Max Logits: A Simple yet Effective Approach for Identifying Unexpected Road Obstacles in Urban-Scene Segmentation (**ICCV** 2021) [[paper]](https://openaccess.thecvf.com/content/ICCV2021/html/Jung_Standardized_Max_Logits_A_Simple_yet_Effective_Approach_for_Identifying_ICCV_2021_paper.html) [[code]](https://github.com/shjung13/Standardized-max-logits)
- Pixel-wise Anomaly Detection in Complex Driving Scenes (**CVPR** 2021) [[paper]](https://openaccess.thecvf.com/content/CVPR2021/html/Di_Biase_Pixel-Wise_Anomaly_Detection_in_Complex_Driving_Scenes_CVPR_2021_paper.html) [[code]](https://github.com/giandbt/SynBoost)

## Review
### 2024
- Vision-Based Traffic Accident Detection and Anticipation: A Survey (**TCSVT** 2024) [[paper]](https://ieeexplore.ieee.org/document/10227352)
- Review of Accident Detection Methods Using Dashcam Videos for Autonomous Driving Vehicles (**TITS** 2024) [[paper]](https://ieeexplore.ieee.org/abstract/document/10417772)

## Datasets
<!-- <hr/> -->

### Contributing
Please help us improve the above listing by submitting PRs of other papers in this space. Thank you!
